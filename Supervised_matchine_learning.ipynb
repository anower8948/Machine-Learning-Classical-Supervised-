{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "255366b8-90c6-4140-9a02-d9197fb022d8",
      "metadata": {
        "id": "255366b8-90c6-4140-9a02-d9197fb022d8"
      },
      "source": [
        "![ML Pipeline](https://media.geeksforgeeks.org/wp-content/uploads/20241022160725494723/supervised-machine-learning.webp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe715e1-134a-450b-8546-d72ab7f224fa",
      "metadata": {
        "id": "7fe715e1-134a-450b-8546-d72ab7f224fa"
      },
      "source": [
        "# Step 1: Import All Essential Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb0f823d-9963-4d70-9375-9500b0fcb755",
      "metadata": {
        "id": "cb0f823d-9963-4d70-9375-9500b0fcb755"
      },
      "source": [
        "1. Import Libraries\n",
        "\n",
        "1.1 Import pandas, numpy, matplotlib, seaborn, sklearn, and joblib.\n",
        "\n",
        "1.2 These libraries help with data handling, visualization, training, and saving models.\n",
        "\n",
        "1.3 Always do this step first to make all tools ready."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22fc3b37-552b-415a-abad-ec302d1a2a24",
      "metadata": {
        "id": "22fc3b37-552b-415a-abad-ec302d1a2a24"
      },
      "outputs": [],
      "source": [
        "# Data Handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning Tools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Machine Learning Models (you can expand later)\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "\n",
        "# Model Evaluation\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, r2_score, mean_squared_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbde20ac-790a-485e-99a1-93f07a2b318c",
      "metadata": {
        "id": "dbde20ac-790a-485e-99a1-93f07a2b318c"
      },
      "source": [
        "# Step 2: Load and Inspect the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e223cc1b-f29e-4058-8bd3-11c48242f279",
      "metadata": {
        "id": "e223cc1b-f29e-4058-8bd3-11c48242f279"
      },
      "source": [
        "2. Load and Inspect Dataset\n",
        "\n",
        "\n",
        "2.1 Load data using pd.read_csv() or similar functions.\n",
        "\n",
        "2.2 Check data shape using df.shape and view top rows using df.head().\n",
        "\n",
        "2.3 Use df.info() and df.describe() to see data types and basic statistics.\n",
        "\n",
        "2.4 Check for missing values with df.isnull().sum().\n",
        "\n",
        "2.5 Check for duplicate rows using df.duplicated().sum()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3c65c1-9a7a-4889-91ae-8353604aadd4",
      "metadata": {
        "id": "ae3c65c1-9a7a-4889-91ae-8353604aadd4"
      },
      "outputs": [],
      "source": [
        "data_path = \"your_dataset.csv\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(data_path)\n",
        "    print(\" Dataset loaded successfully!\\n\")\n",
        "except FileNotFoundError:\n",
        "    print(\" File not found. Check your path or filename.\")\n",
        "\n",
        "# ---- Basic Overview ----\n",
        "print(\" Shape:\", df.shape)\n",
        "print(\"\\n Columns:\", df.columns.tolist())\n",
        "\n",
        "print(\"\\n Data Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\n Summary Statistics (Numerical Features):\")\n",
        "display(df.describe())\n",
        "\n",
        "# ---- Missing Values ----\n",
        "print(\"\\n Missing Values per Column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# ---- Unique Values (for categorical inspection) ----\n",
        "print(\"\\n Unique Values (first 5 categorical columns):\")\n",
        "for col in df.select_dtypes(include='object').columns[:5]:\n",
        "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
        "\n",
        "# ---- Correlation (for numeric features only) ----\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\" Correlation Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3794e0f4-5d06-45ba-80a9-de44d80fd90f",
      "metadata": {
        "id": "3794e0f4-5d06-45ba-80a9-de44d80fd90f"
      },
      "source": [
        "# Step 3: Data Preprocessing (Cleaning + Encoding + Scaling)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa4fdc0c-441f-4d7b-905b-004c84c2362e",
      "metadata": {
        "id": "fa4fdc0c-441f-4d7b-905b-004c84c2362e"
      },
      "source": [
        "3. Data Preprocessing\n",
        "\n",
        "\n",
        "3.1 Handle Missing Values – remove with df.dropna() or fill with fillna().\n",
        "\n",
        "3.2 Encode Categorical Data – use LabelEncoder() or pd.get_dummies().\n",
        "\n",
        "3.3 Split Data – use train_test_split() to make training and testing sets.\n",
        "\n",
        "3.4 Scale Features – use StandardScaler() to keep numeric values in the same range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1cfc16f-bfde-4f8b-9246-c90b00bc80c2",
      "metadata": {
        "id": "f1cfc16f-bfde-4f8b-9246-c90b00bc80c2"
      },
      "outputs": [],
      "source": [
        "# ---- Handle Missing Values ----\n",
        "print(\"\\n Handling Missing Values...\")\n",
        "\n",
        "# Option 1: Drop rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# (Alternative Option)\n",
        "# You can also fill missing values instead of dropping:\n",
        "# df['column_name'].fillna(df['column_name'].mean(), inplace=True)\n",
        "\n",
        "print(\" Missing values handled successfully!\")\n",
        "\n",
        "# ---- Encode Categorical Columns ----\n",
        "print(\"\\n Encoding Categorical Columns...\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_enc = LabelEncoder()\n",
        "\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    df[col] = label_enc.fit_transform(df[col])\n",
        "\n",
        "print(\" Categorical columns encoded!\")\n",
        "\n",
        "# ---- Feature & Target Split ----\n",
        "print(\"\\n Splitting features and target variable...\")\n",
        "\n",
        "# Replace 'target' with your actual target column name\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "print(\" Data split complete.\")\n",
        "print(\"Feature shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)\n",
        "\n",
        "# ---- Train-Test Split ----\n",
        "print(\"\\n Splitting into Train & Test Sets...\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(\" Train-Test split complete!\")\n",
        "print(f\"Training samples: {X_train.shape[0]} | Testing samples: {X_test.shape[0]}\")\n",
        "\n",
        "# ---- Feature Scaling ----\n",
        "print(\"\\n Scaling Numerical Features...\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(\" Feature scaling done successfully!\")\n",
        "\n",
        "# Outlier Removal Example (using IQR)\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "\n",
        "# ---- Encoding Categorical Columns ---\n",
        "# Example categorical columns (replace with yours)\n",
        "# df['Color'], df['Country']\n",
        "\n",
        "#  Label Encoding → use for tree models (DecisionTree, RandomForest, XGBoost)\n",
        "le = LabelEncoder()\n",
        "for col in ['Color', 'Country']:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "print(\" Label Encoding done!\")\n",
        "\n",
        "#  One-Hot Encoding → use for linear models (Logistic, SVM, KNN)\n",
        "# df = pd.get_dummies(df, columns=['Color', 'Country'], drop_first=True)\n",
        "# print(\" One-Hot Encoding done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08bf0b4d-04ca-487f-9bc0-720c7591bfd8",
      "metadata": {
        "id": "08bf0b4d-04ca-487f-9bc0-720c7591bfd8"
      },
      "source": [
        "# STEP 4 – Model Training & Evaluation (Full Detailed Version)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "901f050e-a15e-4c7c-8423-bb183974ec80",
      "metadata": {
        "id": "901f050e-a15e-4c7c-8423-bb183974ec80"
      },
      "source": [
        "4. Model Training and Testing\n",
        "\n",
        "\n",
        "4.1 Choose task type: classification or regression.\n",
        "\n",
        "4.2 Select algorithms:\n",
        "- Classification → Logistic Regression, Decision Tree, Random Forest, SVM, KNN.\n",
        "- Regression → Linear Regression, Decision Tree Regressor, Random Forest Regressor, SVR, KNN Regressor.\n",
        "\n",
        "4.3 Train model using fit(X_train, y_train).\n",
        "\n",
        "4.4 Predict results using predict(X_test).\n",
        "\n",
        "4.5 Check performance using accuracy or R² score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab3e58f-f7fd-46ed-b0d3-368bdc0cdae2",
      "metadata": {
        "id": "6ab3e58f-f7fd-46ed-b0d3-368bdc0cdae2"
      },
      "outputs": [],
      "source": [
        "# STEP 4: Model Training & Evaluation\n",
        "print(\"\\n Starting Model Training & Evaluation...\")\n",
        "\n",
        "#  Choose your task type\n",
        "task_type = \"classification\"   # change to \"regression\" if needed\n",
        "\n",
        "\n",
        "# ====== CLASSIFICATION MODELS ======\n",
        "if task_type == \"classification\":\n",
        "    print(\"\\n Training Classification Models...\\n\")\n",
        "\n",
        "    # 1. Logistic Regression\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, pred))\n",
        "\n",
        "    # 2. Decision Tree\n",
        "    model = DecisionTreeClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    print(\"Decision Tree Accuracy:\", accuracy_score(y_test, pred))\n",
        "\n",
        "    # 3. Random Forest\n",
        "    model = RandomForestClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    print(\"Random Forest Accuracy:\", accuracy_score(y_test, pred))\n",
        "\n",
        "    # 4. SVM\n",
        "    model = SVC()\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    print(\"SVM Accuracy:\", accuracy_score(y_test, pred))\n",
        "\n",
        "    # 5. KNN\n",
        "    model = KNeighborsClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    print(\"KNN Accuracy:\", accuracy_score(y_test, pred))\n",
        "\n",
        "\n",
        "# ====== REGRESSION MODELS ======\n",
        "else:\n",
        "    print(\"\\n Training Regression Models...\\n\")\n",
        "\n",
        "    # 1. Linear Regression\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    print(\"Linear Regression R²:\", r2_score(y_test, pred))\n",
        "\n",
        "    # 2. Decision Tree\n",
        "    model = DecisionTreeRegressor()\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    print(\"Decision Tree R²:\", r2_score(y_test, pred))\n",
        "\n",
        "    # 3. Random Forest\n",
        "    model = RandomForestRegressor()\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    print(\"Random Forest R²:\", r2_score(y_test, pred))\n",
        "\n",
        "    # 4. SVR\n",
        "    model = SVR()\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    print(\"SVR R²:\", r2_score(y_test, pred))\n",
        "\n",
        "    # 5. KNN\n",
        "    model = KNeighborsRegressor()\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    print(\"KNN R²:\", r2_score(y_test, pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d3c091b-8a33-4267-9e73-4d2082e7cf70",
      "metadata": {
        "id": "8d3c091b-8a33-4267-9e73-4d2082e7cf70"
      },
      "source": [
        "# STEP 5: Saving Model & Predicting New Data (All Models Listed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de2e5af5-59d5-4766-a43d-5703898bdfc5",
      "metadata": {
        "id": "de2e5af5-59d5-4766-a43d-5703898bdfc5"
      },
      "source": [
        "5. Save and Predict\n",
        "\n",
        "\n",
        "5.1 Save trained model using joblib.dump(model, 'my_model.pkl').\n",
        "\n",
        "5.2 Load it later using joblib.load('my_model.pkl').\n",
        "\n",
        "5.3 Make predictions on new data using predict()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26c8a849-1565-4b31-ba61-56b7c88f0fd7",
      "metadata": {
        "id": "26c8a849-1565-4b31-ba61-56b7c88f0fd7"
      },
      "outputs": [],
      "source": [
        "# STEP 5: Save Model & Predict New Data\n",
        "print(\"\\n Saving Model & Making Predictions...\")\n",
        "\n",
        "import joblib  # used for saving and loading ML models\n",
        "\n",
        "\n",
        "# ✅ Choose the model you want to save & use\n",
        "# Uncomment only ONE of the following\n",
        "\n",
        "# model = LogisticRegression(max_iter=1000)       # For classification\n",
        "# model = DecisionTreeClassifier()                # For classification\n",
        "# model = RandomForestClassifier()                # For classification\n",
        "# model = SVC()                                   # For classification\n",
        "# model = KNeighborsClassifier()                  # For classification\n",
        "\n",
        "# model = LinearRegression()                      # For regression\n",
        "# model = DecisionTreeRegressor()                 # For regression\n",
        "# model = RandomForestRegressor()                 # For regression\n",
        "# model = SVR()                                   # For regression\n",
        "# model = KNeighborsRegressor()                   # For regression\n",
        "\n",
        "\n",
        "#  Train the selected model again (you can skip if already trained)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ---- Save the trained model ----\n",
        "joblib.dump(model, \"my_model.pkl\")\n",
        "print(\" Model saved as 'my_model.pkl'\")\n",
        "\n",
        "# ---- Load the saved model ----\n",
        "loaded_model = joblib.load(\"my_model.pkl\")\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# ---- Predict using new data ----\n",
        "# Example: replace values with your real input data\n",
        "# (must match the same number of features as X_train)\n",
        "sample_data = [[5.1, 3.5, 1.4, 0.2]]  # example for 4 features\n",
        "prediction = loaded_model.predict(sample_data)\n",
        "\n",
        "print(\"\\n Prediction for sample data:\", prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a7b210b-6554-4283-ba26-b72a83e68d7d",
      "metadata": {
        "id": "1a7b210b-6554-4283-ba26-b72a83e68d7d"
      },
      "source": [
        "# STEP 6: Model Evaluation (All Metrics + Confusion Matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75e3521f-266e-4db3-bd99-8de5759025c2",
      "metadata": {
        "id": "75e3521f-266e-4db3-bd99-8de5759025c2"
      },
      "source": [
        "6. Model Evaluation\n",
        "\n",
        "\n",
        "6.1 For classification:\n",
        "- Use accuracy, precision, recall, F1-score, and confusion matrix.\n",
        "\n",
        "6.2 For regression:\n",
        "- Use R² score, Mean Squared Error (MSE), and Root Mean Squared Error (RMSE).\n",
        "\n",
        "6.3 Compare all models.\n",
        "\n",
        "6.4 The model with higher accuracy or R² and lower error is the best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba207ea3-2e9b-49dd-8657-7e8527344c03",
      "metadata": {
        "id": "ba207ea3-2e9b-49dd-8657-7e8527344c03"
      },
      "outputs": [],
      "source": [
        "# STEP 6: Model Evaluation (Accuracy, Precision, Recall, F1, R2, Confusion Matrix)\n",
        "print(\"\\n Evaluating Model Performance...\")\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report,\n",
        "    r2_score, mean_squared_error\n",
        ")\n",
        "\n",
        "#  Choose your task\n",
        "task_type = \"classification\"   # or \"regression\"\n",
        "\n",
        "# Use your trained model (make sure you already trained one in Step 4 or Step 5)\n",
        "# Example:\n",
        "# model = RandomForestClassifier()\n",
        "# model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# ----- CLASSIFICATION METRICS -----\n",
        "if task_type == \"classification\":\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    rec = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"\\n Classification Metrics:\")\n",
        "    print(f\"Accuracy : {acc:.3f}\")\n",
        "    print(f\"Precision: {prec:.3f}\")\n",
        "    print(f\"Recall   : {rec:.3f}\")\n",
        "    print(f\"F1-Score : {f1:.3f}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\nDetailed Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# ----- REGRESSION METRICS -----\n",
        "else:\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = mse ** 0.5\n",
        "\n",
        "    print(\"\\n Regression Metrics:\")\n",
        "    print(f\"R² Score: {r2:.3f}\")\n",
        "    print(f\"MSE     : {mse:.3f}\")\n",
        "    print(f\"RMSE    : {rmse:.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}